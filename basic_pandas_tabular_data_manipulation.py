# -*- coding: utf-8 -*-
"""Basic Pandas Tabular Data Manipulation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18um5uIO8oyOrswQFAZ6WWz9m-i-HFscW

# Basic Pandas Tabular Data Manipulation

MPG auto dataset
"""

import pandas as pd

df = pd.read_csv("https://data.heatonresearch.com/data/t81-558/auto-mpg.csv")
df[0:5]

# Strip non-numerics
df = df.select_dtypes(include=['int', 'float'])

headers = list(df.columns.values)
fields = []

for field in headers:
    fields.append({
        'name' : field,
        'mean': df[field].mean(),
        'var': df[field].var(),
        'sdev': df[field].std()
    })

for field in fields:
    print(field)

df = pd.DataFrame(fields)
df

"""# Missing Values

Dealing with Missing Values is always a factor in Machine Learning. First We will recal the csv and  
fill empty values with NAN
"""

df[32:33]

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv", 
    na_values=['NA', '?'])
print(f"Does Horsepower have any na values? {pd.isnull(df['horsepower']).values.any()}")

df[32:33]

"""Now we will fill these missing values with the median values of horsepower. It is better to use the median than mean due to outliters in the data set."""

med = df['horsepower'].median()
df['horsepower'] = df['horsepower'].fillna(med)

print(f"Does Horsepower have any na values? {pd.isnull(df['horsepower']).values.any()}")

"""# Dealing With Ouliers

these are values in the data that are unsually high or low. These tend to be defiend by the value being serval standard deviations away for the mean.
"""

# Removes all all rows where the specified column is +/- standard deviations

def remove_outliers(df, name, sd):
    drop_rows = df.index[(np.abs(df[name] - df[name].mean())
                          >= (sd * df[name].std()))]
    df.drop(drop_rows, axis=0, inplace=True)

import pandas as pd
import os
import numpy as np
from sklearn import metrics
from scipy.stats import zscore

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

# create feature vector
med = df['horsepower'].median()
df['horsepower'] = df['horsepower'].fillna(med)

# Drop the name column
df.drop('name',1,inplace=True)

# Drop outliers in horsepower
print("Length before MPG outliers dropped: {}".format(len(df)))
remove_outliers(df,'mpg',2)
print("Length after MPG outliers dropped: {}".format(len(df)))

display(df[0:5])

"""# Dropping Fields

some fields have little to know value for the nueral network. These columns will be removed with the code below.
"""

import pandas as pd
import os


df = pd.read_csv("https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

print(f"Before Droped Columns: {list(df.columns)}")
df.drop('name', 1, inplace=True)
print(f"Before Droped Columns: {list(df.columns)}")

"""# Concatenating Row

Create new dataframes by combinding row and columns together.
"""

# Create a new dataframe from name and horsepower

import os
import pandas as pd

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

col_horsepower = df['horsepower']
col_name = df['name']
result = pd.concat([col_name, col_horsepower], axis=1)
display(result[0:5])

# Create a new dataframe from first 2 rows and last 2 rows

import os
import pandas as pd

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

result = pd.concat([df[0:2],df[-2:]], axis=0)
display(result)

"""# Training and Validation

it is very important that we evaluate a machine learning model based on its ability to predict data that it has never seen before. Because of this we often divide the training data into a validation and training set. The machine learning model will learn from the training data, but ultimately be evaluated based on the validation data.

Training Data - In Sample Data - The data that the machine learning model was fit to/created from.
Validation Data - Out of Sample Data - The data that the machine learning model is evaluated upon after it is fit to the training data.
There are two predominant means of dealing with training and validation data:

Training/Validation Split - The data are split according to some ratio between a training and validation (hold-out) set. Common ratios are 80% training and 20% validation.
K-Fold Cross Validation - The data are split into a number of folds and models. Because a number of models equal to the folds is created out-of-sample predictions can be generated for the entire dataset.
The code below performs a split of the MPG data into a training and validation set. The training set uses 80% of the data and the validation set uses 20%.

The following image shows how a model is trained on 80% of the data and then validated against the remaining 20%.
"""

import os
import pandas as pd
import numpy as np

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

df = df.reindex(np.random.permutation(df.index)) # Usually a good idea to shuffle
mask = np.random.rand(len(df)) < 0.8
trainDF = pd.DataFrame(df[mask])
validationDF = pd.DataFrame(df[~mask])

print(f"Training DF: {len(trainDF)}")
print(f"Validation DF: {len(validationDF)}")

"""# Converting a Dataframe to a Matrix

Converting a Dataframe to a Matrix
Neural networks do not directly operate on Python dataframes. A neural network requires a numeric matrix. The values property of a dataframe is used to convert to a matrix.
"""

df.values

df[['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',
       'acceleration', 'year', 'origin']].values

"""# Saving a Dataframe to CSV
Many of the assignments in this course will require that you save a dataframe to submit to the instructor. The following code performs a shuffle and then saves a new copy.
"""

import os
import pandas as pd
import numpy as np

path = "."

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

filename_write = os.path.join(path, "auto-mpg-shuffle.csv")
df = df.reindex(np.random.permutation(df.index))
df.to_csv(filename_write, index=False) # Specify index = false to not write row numbers
print("Done")

"""# Saving a Dataframe to Pickle
CSV files are text and can be used by a variety of software programs. However, they do take longer to generate and can sometimes lose small amounts of precision in the conversion. Another format is Pickle. Generally you will output to CSV because it is very compatible, even outside of Python. The code below stores the Dataframe to Pickle.
"""

import os
import pandas as pd
import numpy as np
import pickle

path = "."

df = pd.read_csv(
    "https://data.heatonresearch.com/data/t81-558/auto-mpg.csv",
    na_values=['NA','?'])

filename_write = os.path.join(path, "auto-mpg-shuffle.pkl")
df = df.reindex(np.random.permutation(df.index))

with open(filename_write,"wb") as fp:
    pickle.dump(df, fp)

print("Done")